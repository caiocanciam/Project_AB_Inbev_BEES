{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a270a5-5686-4276-bbff-4a593003f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.sql.functions import coalesce, col\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78cc9c7-5166-452f-ab21-2593d0075590",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Breweries\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f7bd898-06a8-4f4e-b4ea-e5f269e42c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_url = \"/home/jovyan/work/layers/bronze/\"\n",
    "output_path = \"/home/jovyan/work/layers/silver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be5e2e31-22d2-482e-aef8-a5de5bb62991",
   "metadata": {},
   "outputs": [],
   "source": [
    "todos_dados = []\n",
    "\n",
    "for arquivo in os.listdir(input_url):\n",
    "    if arquivo.endswith(\".json\"): # Get only .json\n",
    "        caminho = os.path.join(input_url, arquivo)\n",
    "        with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
    "            dados = json.load(f)\n",
    "            todos_dados.append(dados)\n",
    "\n",
    "df_spark = spark.read.option(\"multiline\", \"true\").json(input_url)\n",
    "\n",
    "# Converter tudo para string\n",
    "df_spark = df_spark.select([F.col(c).cast(\"string\").alias(c) for c in df_spark.columns])\n",
    "\n",
    "# Se 'city' não existir ou estiver vazio, usar 'state_province'\n",
    "df_silver = df_spark.withColumn(\n",
    "    \"brewery_location\",\n",
    "    coalesce(col(\"city\"), col(\"state_province\"))\n",
    ")\n",
    "\n",
    "# 2. Remover duplicados (pelo ID)\n",
    "df_silver = df_silver.dropDuplicates([\"id\"])\n",
    "\n",
    "date = str(datetime.now(pytz.timezone(\"Brazil/East\"))).split(\" \")[0]\n",
    "\n",
    "df_silver = df_silver.withColumn(\"exec_date\", F.to_date(F.lit(date)))\n",
    "\n",
    "# 3. Salvar no formato Parquet, particionando por localização (state)\n",
    "df_silver.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"brewery_location\") \\\n",
    "    .parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04a384b-cf48-408a-ac47-e91cb27f9c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+-------------+--------------------+--------------+----------+\n",
      "|brewery_type|            city|      country|                name|         state| exec_date|\n",
      "+------------+----------------+-------------+--------------------+--------------+----------+\n",
      "|     brewpub|      Louisville|United States|    12Degree Brewing|      Colorado|2025-08-08|\n",
      "|       micro|         Houston|United States|11 Below Brewing ...|         Texas|2025-08-08|\n",
      "|       micro|            Mesa|United States|12 West Brewing C...|       Arizona|2025-08-08|\n",
      "|       large|          Denver|United States|10 Barrel Brewing...|      Colorado|2025-08-08|\n",
      "|       micro|       Milwaukee|United States|1840 Brewing Company|     Wisconsin|2025-08-08|\n",
      "|       micro|            Reno|United States|10 Torr Distillin...|        Nevada|2025-08-08|\n",
      "|       micro|        Abington|United States|10th District Bre...| Massachusetts|2025-08-08|\n",
      "|       micro|      Georgetown|United States|  16 Mile Brewing Co|      Delaware|2025-08-08|\n",
      "|       micro|  Mount Pleasant|United States|1 of Us Brewing C...|     Wisconsin|2025-08-08|\n",
      "|       micro|           Anoka|United States|         10K Brewing|     Minnesota|2025-08-08|\n",
      "|     brewpub|         Taylors|United States|  13 Stripes Brewery|South Carolina|2025-08-08|\n",
      "|       micro|         okolona|United States|        1817 Brewery|   Mississippi|2025-08-08|\n",
      "|       micro|Westlake Village|United States|14 Cannons Brewin...|    California|2025-08-08|\n",
      "|  proprietor|          Denver|United States|14er Brewing Company|      Colorado|2025-08-08|\n",
      "|       micro|         Kenmore|United States|         192 Brewing|    Washington|2025-08-08|\n",
      "|       micro|          Tucson|United States|        1912 Brewing|       Arizona|2025-08-08|\n",
      "|       micro|     Castle Rock|United States| 105 West Brewing Co|      Colorado|2025-08-08|\n",
      "|       micro|      Saint Paul|United States|12welve Eyes Brewing|     Minnesota|2025-08-08|\n",
      "|       micro|          Norman|United States|    (405) Brewing Co|      Oklahoma|2025-08-08|\n",
      "|     brewpub|        John Day|United States|     1188 Brewing Co|        Oregon|2025-08-08|\n",
      "+------------+----------------+-------------+--------------------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_silver.select('brewery_type', 'city', 'country', 'name', 'state', 'exec_date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba02f36e-a962-40bb-9b45-bdcb5505c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar dados no SQLite\n",
    "def save_to_sqlite():\n",
    "    try:\n",
    "        input_path = '/opt/airflow/dags/dados_transformados.csv'\n",
    "        if not os.path.exists(input_path):\n",
    "            raise FileNotFoundError(f\"Arquivo {input_path} não encontrado!\")\n",
    "        conn = sqlite3.connect('/opt/airflow/dags/meu_banco.db')\n",
    "        df = pd.read_csv(input_path, encoding='utf-8')\n",
    "        df.to_sql('transacoes', conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        print(\"Dados carregados no SQLite com sucesso!\")\n",
    "        print(f\"Verificando existência do arquivo: {os.path.exists('/opt/airflow/dags/meu_banco.db')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar no SQLite: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Definindo a DAG\n",
    "with DAG(\n",
    "    dag_id='etl_pipeline_2',\n",
    "    start_date=datetime(2025, 3, 16),\n",
    "    schedule_interval=None,\n",
    "    catchup=False,\n",
    ") as dag:\n",
    "    load = PythonOperator(task_id='load_file', python_callable=load_file)\n",
    "    transform = PythonOperator(task_id='transform_data', python_callable=transform_data)\n",
    "    save = PythonOperator(task_id='save_to_sqlite', python_callable=save_to_sqlite)\n",
    "    load >> transform >> save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdbca693-2531-4ff6-9e82-1b2286f0e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pandas = pd.json_normalize(dados_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32eaff9-b7ce-46d1-99ca-2bb617fd7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pandas.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
